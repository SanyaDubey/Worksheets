{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING WORKSHEET - 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Which of the following in sk-learn library is used for hyper parameter tuning?\n",
    "###### A) GridSearchCV() \n",
    "###### B) RandomizedCV()\n",
    "###### C) K-fold Cross Validation \n",
    "###### D) All of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. A) GridSearchCV()\n",
    "         B) RandomizedCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. In which of the below ensemble techniques trees are trained in parallel?\n",
    "###### A) Random forest \n",
    "###### B) Adaboost\n",
    "###### C) Gradient Boosting \n",
    "###### D) All of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. A) Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. In machine learning, if in the below line of code: sklearn.svm.SVC (C=1.0, kernel='rbf', degree=3) we increasing the C hyper parameter, what will happen?\n",
    "###### A) The regularization will increase \n",
    "###### B) The regularization will decrease\n",
    "###### C) No effect on regularization\n",
    "###### D) kernel will be changed to linear "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. B) The regularization will decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Check the below line of code and answer the following questions: sklearn.tree.DecisionTreeClassifier(*criterion='gini',splitter='best',max_depth=None, min_samples_split=2). Which of the following is true regarding max_depth hyper parameter?\n",
    "###### A) It regularizes the decision tree by limiting the maximum depth up to which a tree can be grown.\n",
    "###### B) It denotes the number of children a node can have.\n",
    "###### C) both A & B\n",
    "###### D) None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. A) It regularizes the decision tree by limiting the maximum depth up to which a tree can be grown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5. Which of the following is true regarding Random Forests?\n",
    "###### A) It's an ensemble of weak learners.\n",
    "###### B) The component trees are trained in series\n",
    "###### C) In case of classification problem, the prediction is made by taking mode of the class labels predicted by the component trees.\n",
    "###### D)None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. C) In case of classification problem, the prediction is made by taking mode of the class labels predicted by \n",
    "            the component trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6. What can be the disadvantage if the learning rate is very high in gradient descent?\n",
    "###### A) Gradient Descent algorithm can diverge from the optimal solution.\n",
    "###### B) Gradient Descent algorithm can keep oscillating around the optimal solution and may not settle.\n",
    "###### C) Both of them\n",
    "###### D) None of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. A) Gradient Descent algorithm can diverge from the optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 7. As the model complexity increases, what will happen?\n",
    "###### A) Bias will increase, Variance decrease \n",
    "###### B) Bias will decrease, Variance increase\n",
    "###### C)both bias and variance increase \n",
    "###### D) Both bias and variance decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. B) Bias will decrease, Variance increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 8. Suppose I have a linear regression model which is performing as follows: Train accuracy=0.95 and Test accuracy=0.75. Which of the following is true regarding the model?\n",
    "###### A) model is underfitting \n",
    "###### B) model is overfitting\n",
    "###### C) model is performing good \n",
    "###### D) None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. B) model is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9 to Q15 are subjective answer type questions, Answer them briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 9. Suppose we have a dataset which have two classes A and B. The percentage of class A is 40% and percentage of class B is 60%. Calculate the Gini index and entropy of the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Class A = 40%\n",
    "    Class B = 60%\n",
    "    \n",
    "    Gini Index = 1 - [(P+)^2 +(P-)^2]\n",
    "               = 1 - [(2/5)^2 + (3/5)^2]\n",
    "               = 12/25\n",
    "               = 0.48                            \n",
    "                    \n",
    "    Entropy = -p log2p – q log2q\n",
    "            = -(40/100) log2(40/100) + (60/100) log2(60/100)\n",
    "            = 0.96                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 10. What are the advantages of Random Forests over Decision Tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    A random forest is simply a collection of decision trees whose results are aggregated into one final result. Their \n",
    "    ability to limit overfitting without substantially increasing error due to bias is why they are such powerful model and\n",
    "    thus it is much more robust than a single decision tree.\n",
    "    One way Random Forests reduce variance is by training on different samples of the data.\n",
    "    The random forest chooses features randomly during the training process. Therefore, it does not depend highly on \n",
    "    any specific set of features. Therefore, the random forest can generalize over the data in a better way. This \n",
    "    randomized feature selection makes random forest much more accurate than a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 11. What is the need of scaling all numerical features in a dataset? Name any two techniques used for scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    There is a need of scaling all numerical features ina  dataset because:\n",
    "        - The gradient descent algorithm which is used to reach the optimal solution in most of the cases, it reached the \n",
    "          optimal solution much faster if all the features are at the same scale. That’s why scaling helps to reach the\n",
    "          optimal solution. \n",
    "        - If the features in the dataset are on different scales, then during training the features with large scales will \n",
    "          be favored over there in order to minimize the loss. That’s why feature scaling is done to put all the features on \n",
    "          the same scale. \n",
    "    \n",
    "    The most common techniques of feature scaling are:\n",
    "    - Min Max Scaler.\n",
    "    - Standard Scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 12. Write down some advantages which scaling provides in optimization using gradient descent algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Optimization refers to the task of minimizing/maximizing an objective function f(x) parameterized by x. In machine/\n",
    "    deep learning terminology, it’s the task of minimizing the cost/loss function J(w) parameterized by the model’s \n",
    "    parameters w ∈ R^d.\n",
    "\n",
    "    Gradient Descent is the most common optimization algorithm in machine learning and deep learning. It is a first-\n",
    "    order optimization algorithm. \n",
    "    \n",
    "    Advantages:\n",
    "        •We can use fixed learning rate during training without worrying about learning rate decay.\n",
    "        •It has straight trajectory towards the minimum and it is guaranteed to converge in theory to the global\n",
    "         minimum if the loss function is convex and to a local minimum if the loss function is not convex.\n",
    "        •It has unbiased estimate of gradients. The more the examples, the lower the standard error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 13. In case of a highly imbalanced dataset for a classification problem, is accuracy a good metric to measure the performance of the model. If not, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Accuracy is not the best metric to use when evaluating imbalanced datasets as it can be misleading as it does \n",
    "    not distinguish between the numbers of correctly classified examples of different classes. Hence, it may lead\n",
    "    to erroneous conclusions \n",
    "    \n",
    "    Metrics that can provide better insight are:\n",
    "        - Confusion Matrix: a table showing correct predictions and types of incorrect predictions.\n",
    "        - Precision: the number of true positives divided by all positive predictions. Precision is also called \n",
    "                     Positive Predictive Value. It is a measure of a classifier’s exactness. Low precision indicates a \n",
    "                     high number of false positives.\n",
    "        - Recall: the number of true positives divided by the number of positive values in the test data. The recall is \n",
    "                  also called Sensitivity or the True Positive Rate. It is a measure of a classifier’s completeness. Low\n",
    "                  recall indicates a high number of false negatives.\n",
    "        - F1: Score: the weighted average of precision and recall.\n",
    "        - Area Under ROC Curve (AUROC): AUROC represents the likelihood of your model distinguishing observations from \n",
    "                                        two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 14. What is “f-score\" metric? Write its mathematical formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The F-score, also called the F1-score, is a measure of a model’s accuracy on a dataset. It is used to evaluate\n",
    "    binary classification systems, which classify examples into ‘positive’ or ‘negative’.\n",
    "    The F-score is a way of combining the precision and recall of the model, and it is defined as the harmonic mean of\n",
    "    the model’s precision and recall.\n",
    "    \n",
    "    The formula for the standard F1-score is the harmonic mean of the precision and recall. A perfect model has an F-score \n",
    "    of 1.\n",
    "    Its mathematical formula:\n",
    "                            F-Measure = (2 * Precision * Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 15. What is the difference between fit(), transform() and fit_transform()?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    fit(), transform() and fit_transform() are used in both for transformers and for models.\n",
    "    \n",
    "        - Transformers are for pre-processing before modeling. The Imputer class and FeatureSelection classes in sklearn \n",
    "          are an example of some transformers.\n",
    "        - Models are used to make predictions.\n",
    "        \n",
    "    For Transformers:\n",
    "        - fit() - It is used for calculating the initial filling of parameters on the training data (like mean of the \n",
    "                  values) and saves them as an internal objects state\n",
    "        - transform() - Use the above calculated values and return modified training data\n",
    "        - fit_transform() - It joins above two steps. Internally, it just calls first fit() and then transform() on the\n",
    "                            same data.\n",
    "                            \n",
    "    For Models:\n",
    "        - fit() - It calculates the parameters/weights on training data and saves them as an internal objects state.\n",
    "        - transform() - Cannot be used\n",
    "        - fit_transform() - Cannot be used"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
