{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING WORKSHEET - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  In Q1 to Q7, only one option is correct, Choose the correct option:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. The value of correlation coefficient will always be:\n",
    "###### A) between 0 and 1 \n",
    "###### B) greater than -1\n",
    "###### C) between -1 and 1 \n",
    "###### D) between 0 and -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. C) between -1 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Which of the following cannot be used for dimensionality reduction?\n",
    "###### A) Lasso Regularisation\n",
    "###### B) PCA\n",
    "###### C) Recursive feature elimination \n",
    "###### D) Ridge Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. D) Ridge Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Which of the following is not a kernel in Support Vector Machines?\n",
    "###### A) linear \n",
    "###### B) Radial Basis Function\n",
    "###### C) hyperplane \n",
    "###### D) polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. C) hyperplane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Amongst the following, which one is least suitable for a dataset having non-linear decision boundaries?\n",
    "###### A) Logistic Regression \n",
    "###### B) Naïve Bayes Classifier\n",
    "###### C) Decision Tree Classifier \n",
    "###### D) Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. A) Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5. In a Linear Regression problem, ‘X’ is independent variable and ‘Y’ is dependent variable, where ‘X’ represents weight in pounds. If you convert the unit of ‘X’ to kilograms, then new coefficient of ‘X’ will be?\n",
    "###### (1 kilogram = 2.205 pounds)\n",
    "###### A) 2.205 × old coefficient of ‘X’ \n",
    "###### B) same as old coefficient of ‘X’\n",
    "###### C) old coefficient of ‘X’ ÷ 2.205 \n",
    "###### D) Cannot be determined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. C) old coefficient of ‘X’ ÷ 2.205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6. As we increase the number of estimators in ADABOOST Classifier, what happens to the accuracy of the model?\n",
    "###### A) remains same \n",
    "###### B) increases\n",
    "###### C) decreases \n",
    "###### D) none of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. B) increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 7. Which of the following is not an advantage of using random forest instead of decision trees?\n",
    "###### A) Random Forests reduce overfitting\n",
    "###### B) Random Forests explains more variance in data then decision trees\n",
    "###### C) Random Forests are easy to interpret\n",
    "###### D) Random Forests provide a reliable feature importance estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. C) Random Forests are easy to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Q8 to Q10, more than one options are correct, Choose all the correct options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 8. Which of the following are correct about Principal Components?\n",
    "###### A) Principal Components are calculated using supervised learning techniques\n",
    "###### B) Principal Components are calculated using unsupervised learning techniques\n",
    "###### C) Principal Components are linear combinations of Linear Variables.\n",
    "###### D) All of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. B) Principal Components are calculated using unsupervised learning techniques, \n",
    "         C) Principal Components are linear combinations of Linear Variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 9. Which of the following are applications of clustering?\n",
    "###### A) Identifying developed, developing and under-developed countries on the basis of factors like GDP, poverty index, employment rate, population and living index\n",
    "###### B) Identifying loan defaulters in a bank on the basis of previous years’ data of loan accounts.\n",
    "###### C) Identifying spam or ham emails\n",
    "###### D) Identifying different segments of disease based on BMI, blood pressure, cholesterol, blood sugar levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. A) Identifying developed, developing and under-developed countries on the basis of factors like GDP, poverty index,\n",
    "            employment rate, population and living index\n",
    "         D) Identifying different segments of disease based on BMI, blood pressure, cholesterol, blood sugar levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 10. Which of the following is(are) hyper parameters of a decision tree?\n",
    "###### A) max_depth \n",
    "###### B) max_features\n",
    "###### C) n_estimators \n",
    "###### D) min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. A) max_depth, \n",
    "         B) max_features, \n",
    "         D) min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10 to Q15 are subjective answer type questions, Answer them briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 11. What are outliers? Explain the Inter Quartile Range (IQR) method for outlier detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    An outlier is an observation that lies an abnormal distance from other values in a random sample from a population. \n",
    "    In a sense, this definition leaves it up to the analyst to decide what will be considered abnormal.\n",
    "    For eg: While analyzing salaries of all the people in India, salary of Mukesh Ambani or Ratan Tata might be an outlier.\n",
    "    \n",
    "    Inter Quartile Range (IQR):\n",
    "                                IQR = Q3-Q1\n",
    "                                \n",
    "    Where, Q1 = 25th % ile of the data\n",
    "    Q2 = 50th % ile (a.k.a. median)\n",
    "    Q3 = 75th % ile of the data.\n",
    "    Upper bound = Q3 + 1.5*IQR\n",
    "    Lower Bound = Q1 – 1.5*IQR\n",
    "    \n",
    "    Any data point lying above than upper bound and lower than lower bound is considered as an outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 12. What is the primary difference between bagging and boosting algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging: \n",
    "    \n",
    "    Bagging is also known as bootstrap aggregating sits on top of the majority voting principle. The samples are \n",
    "    bootstrapped each time when the model is trained. When the samples are chosen, they are used to train and validate \n",
    "    the predictions. The samples are then replaced back into the training set. The samples are selected at random. \n",
    "    This technique is known as bagging. To sum up, base classifiers such as decision trees are fitted on random subsets of \n",
    "    the original training set. Subsequently, the individual predictions are aggregated (voting or averaging etc.). The final \n",
    "    results are then used as predictions. It reduces the variance of a black box estimator. Due to this the chances\n",
    "    of overfitting is ruled out.\n",
    "    \n",
    "    \n",
    "Boosting: \n",
    "\n",
    "    The concept of Adaptive Boost revolves around correcting previous classifier mistakes. Each classifier gets trained on \n",
    "    the sample set and learns to predict. The misclassification errors are then fed into the next classifier in the chain \n",
    "    and are used to correct the mistakes until the final model predicts accurate results. When a weak-classifier \n",
    "    misclassifies a training sample, the algorithm then uses these very samples to improve the performance of the ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 13. What is adjusted R2 in linear regression. How is it calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Adjusted R2 and R2 both represent that how well the model fits the data points. But adjusted R2 penalizes the model \n",
    "    for using more features. In case we increase the number of features in training data the R2 will increase but adjusted \n",
    "    R2 will only increase if the new feature adds value to our model. Due to this reason adjusted R2 is considered as a \n",
    "    better evaluation metric than R2. Adjusted R2 is always less than or equal to R2. \n",
    "    \n",
    "    The formula to calculate adjusted R2 is as follows:\n",
    "                                           R2adj=1−[(1−R2)(n−1)n−k−1]\n",
    "                                           \n",
    "    Where,\n",
    "    n = number of data points in the dataset\n",
    "    K = Number of features in the dataset excluding the constant term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 14. What is the difference between standardisation and normalisation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    In Normalization a dataset is scaled in such a way that all the data points lie between 0 and 1. Normalization is \n",
    "    often called min-max scaling. \n",
    "    Formula for Normalization is as follows:\n",
    "                                            X' = (X - X_min)/(X_max - X_min)\n",
    "    Where, X_max and X_min are the maximum and the minimum values of the feature respectively.\n",
    "    \n",
    "    Whereas, In Standardization a dataset is scaled in such a way that the mean of data points becomes 0 and standard \n",
    "    deviation is 1. The transformed data may be positive as well as negative in standardization. \n",
    "    The formula for standardization is as follows:\n",
    "                                                 X' = (X - μ)/σ\n",
    "    Where,\n",
    "    μ = mean of the feature values\n",
    "    σ = standard deviation of the feature values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 15. What is cross-validation? Describe one advantage and one disadvantage of using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Cross validation is a technique to fit a model on data set. In cross validation the data set is divided into ‘k’ number \n",
    "    of sets where ‘k-1’ sets are used for training and 1 set is used as validation set. And this is done for all the set one \n",
    "    by one and the final score of model is taken as average score of all the ‘k’ number of fits. \n",
    "    \n",
    "    Advantage of using Cross validation is that, there is no need of separate validation data, cross validation reduces \n",
    "    chances of overfitting and gives a more generic model. \n",
    "    \n",
    "    Cross validation has a disadvantage that it takes more time to fit the model over a large dataset and the model built \n",
    "    is more complex than the basic model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
