{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Q1 to Q7, only one option is correct, Choose the correct option:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. What is the advantage of hierarchical clustering over K-means clustering?\n",
    "###### A) Hierarchical clustering is computationally less expensive\n",
    "###### B) In hierarchical clustering you don’t need to assign number of clusters in beginning\n",
    "###### C) Both are equally proficient\n",
    "###### D) None of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. C) Both are equally proficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Which of the following hyper parameter(s), when increased may cause random forest to over fit the data?\n",
    "###### A) max_depth \n",
    "###### B) n_estimators \n",
    "###### C) min_samples_leaf \n",
    "###### D) min_samples_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. A) max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Which of the following is the least preferable resampling method in handling imbalance datasets?\n",
    "###### A) SMOTE \n",
    "###### B) RandomOverSampler\n",
    "###### C) RandomUnderSampler \n",
    "###### D) ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. D) ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Which of the following statements is/are true about “Type-1” and “Type-2” errors?\n",
    "###### 1. Type1 is known as false positive and Type2 is known as false negative.\n",
    "###### 2. Type1 is known as false negative and Type2 is known as false positive.\n",
    "###### 3. Type1 error occurs when we reject a null hypothesis when it is actually true.\n",
    "\n",
    "###### A) 1 and 2 \n",
    "###### B) 1 only\n",
    "###### C) 1 and 3 \n",
    "###### D) 2 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. C) 1 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5. Arrange the steps of k-means algorithm in the order in which they occur:\n",
    "###### 1. Randomly selecting the cluster centroids\n",
    "###### 2. Updating the cluster centroids iteratively\n",
    "###### 3. Assigning the cluster points to their nearest center\n",
    "###### A) 3-1-2 \n",
    "###### B) 2-1-3\n",
    "###### C) 3-2-1 \n",
    "###### D) 1-3-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. D) 1-3-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6. Which of the following algorithms is not advisable to use when you have limited CPU resources and time, and when the data set is relatively large?\n",
    "###### A) Decision Trees \n",
    "###### B) Support Vector Machines\n",
    "###### C) K-Nearest Neighbors\n",
    "###### D) Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. B) Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 7. What is the main difference between CART (Classification and Regression Trees) and CHAID (Chi Square Automatic Interaction Detection) Trees?\n",
    "###### A) CART is used for classification, and CHAID is used for regression.\n",
    "###### B) CART can create multiway trees (more than two children for a node), and CHAID can only create binary trees (a maximum of two children for a node).\n",
    "###### C) CART can only create binary trees (a maximum of two children for a node), and CHAID can create multiway trees (more than two children for a node)\n",
    "###### D) None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. C) CART can only create binary trees (a maximum of two children for a node), and CHAID can create multiway trees \n",
    "            (more than two children for a node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Q8 to Q10, more than one options are correct, Choose all the correct options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 8. In Ridge and Lasso regularization if you take a large value of regularization constant(lambda), which of the following things may occur?\n",
    "###### A) Ridge will lead to some of the coefficients to be very close to 0\n",
    "###### B) Lasso will lead to some of the coefficients to be very close to 0\n",
    "###### C) Ridge will cause some of the coefficients to become 0\n",
    "###### D) Lasso will cause some of the coefficients to become 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. A) Ridge will lead to some of the coefficients to be very close to 0\n",
    "         D) Lasso will cause some of the coefficients to become 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 9. Which of the following methods can be used to treat two multi-collinear features?\n",
    "###### A) remove both features from the dataset\n",
    "###### B) remove only one of the features \n",
    "###### C) Use ridge regularization \n",
    "###### D) use Lasso regularization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. B) remove only one of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 10. After using linear regression, we find that the bias is very low, while the variance is very high. What are the possible reasons for this?\n",
    "###### A) Overfitting \n",
    "###### B) Multicollinearity\n",
    "###### C) Underfitting \n",
    "###### D) Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ANS. A) Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10 to Q15 are subjective answer type questions, Answer them briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 11. In which situation One-hot encoding must be avoided? Which encoding technique can be used in such a case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    When the feature values depict ranking, one hot encoding cannot be applied. In this case, label encoding can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 12. In case of data imbalance problem in classification, what techniques can be used to balance the dataset? Explain them briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Tchniques used to balance the dataset, in case of data imbalance problem in classification:\n",
    "        \n",
    "    1-  Random Under-Sampling\n",
    "        Random Undersampling aims to balance class distribution by randomly eliminating majority class examples. This is \n",
    "        done until the majority and minority class instances are balanced out.\n",
    "\n",
    "    2-  Random Over-Sampling\n",
    "        Over-Sampling increases the number of instances in the minority class by randomly replicating them in order to \n",
    "        present a higher representation of the minority class in the sample.\n",
    "\n",
    "    3-  Cluster-Based Over Sampling\n",
    "        In this case, the K-means clustering algorithm is independently applied to minority and majority class instances. \n",
    "        This is to identify clusters in the dataset. Subsequently, each cluster is oversampled such that all clusters of \n",
    "        the same class have an equal number of instances and all classes have the same size. \n",
    "\n",
    "    4-  Informed Over Sampling: (SMOTE) Synthetic Minority Over-sampling Technique for imbalanced data\n",
    "        This technique is followed to avoid overfitting which occurs when exact replicas of minority instances are added to\n",
    "        the main dataset. A subset of data is taken from the minority class as an example and then new synthetic \n",
    "        similar instances are created. These synthetic instances are then added to the original dataset. The new dataset is \n",
    "        used as a sample to train the classification models. \n",
    "\n",
    "    5-  Modified synthetic minority oversampling technique (MSMOTE) for imbalanced data\n",
    "        It is a modified version of SMOTE. SMOTE does not consider the underlying distribution of the minority class and \n",
    "        latent noises in the dataset. To improve the performance of SMOTE a modified method MSMOTE is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 13. What is the difference between SMOTE and ADASYN sampling techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    SMOTE: Synthetic Minority Over sampling Technique (SMOTE) algorithm applies KNN approach where it selects K \n",
    "           nearest neighbors, joins them and creates the synthetic samples in the space. The algorithm takes the feature \n",
    "           vectors and its nearest neighbors, computes the distance between these vectors. The difference is multiplied \n",
    "           by random number between (0, 1) and it is added back to feature. SMOTE algorithm is a pioneer algorithm and\n",
    "           many other algorithms are derived from SMOTE.\n",
    "           \n",
    "     ADASYN: AdAptive SYNthetic (ADASYN) is based on the idea of adaptively generating minority data samples according to\n",
    "             their distributions using K nearest neighbor. The algorithm adaptively updates the distribution and there are \n",
    "             no assumptions made for the underlying distribution of the data.  The algorithm uses Euclidean distance for\n",
    "             KNN Algorithm. The key difference between ADASYN and SMOTE is that the former uses a density distribution, as\n",
    "             a criterion to automatically decide the number of synthetic samples that must be generated for each minority \n",
    "             sample by adaptively changing the weights of the different minority samples to compensate for the \n",
    "             skewed distributions. The latter generates the same number of synthetic samples for each original minority \n",
    "             sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 14. What is the purpose of using GridSearchCV? Is it preferable to use in case of large datasets? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    GridSearchCV is a library function that is a member of sklearn's model_selection package. It helps to loop \n",
    "    through predefined hyperparameters and fit your estimator (model) on your training set. So, in the end, you can select\n",
    "    the best parameters from the listed hyperparameters. \n",
    "\n",
    "    For very large dataset we cannot use GridSearchCV because it takes too much time although you can use RandomizeSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 15. List down some of the evaluation metric used to evaluate a regression model. Explain each of them in brief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
